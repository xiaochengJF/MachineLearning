{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "决策树:ID3C4.5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXLpfwHNZqCrb9IA963QqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/MachineLearning/blob/master/%E5%86%B3%E7%AD%96%E6%A0%91_ID3C4_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um2P_uVaLCtC",
        "colab_type": "text"
      },
      "source": [
        "# 决策树ID3、C4.5\n",
        "　\n",
        "## ID3\n",
        "- ID3没有考虑连续特征，比如长度，密度都是连续值(没考虑可以自己加)\n",
        "\n",
        "- ID3采用信息增益大的特征优先建立决策树的节点，但相同条件下，取值比较多的特征比取值少的特征信息增益大。如：一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，两者都是完全不确定的变量，但是取3个值的比取2个值的信息增益大\n",
        "\n",
        "- ID3算法对于缺失值的情况没有做考虑\n",
        "\n",
        "- 没有考虑过拟合的问题\n",
        "\n",
        "## C4.5\n",
        "- 剪枝方法主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。C4.5用的前者\n",
        "\n",
        "- C4.5生成的是多叉树，即一个父节点可以有多个节点。在计算机中二叉树模型会比多叉树运算效率高\n",
        "\n",
        "- C4.5只能用于分类\n",
        "\n",
        "- C4.5由于使用了熵模型，里面有大量的耗时的对数运算(<font color=skyblue>但求log是防止计算溢出的利器，特别适合用于处理极小概率的情况</font>)，如果是连续值还有大量的排序运算\n",
        "\n",
        "## 参考文献\n",
        "【1】[计算Gini指数示例](https://sefiks.com/2018/08/27/a-step-by-step-cart-decision-tree-example/)  \n",
        "【2】[机器学习算法实践-决策树(Decision Tree)](http://pytlab.github.io/2017/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5-%E5%86%B3%E7%AD%96%E6%A0%91/)  \n",
        "【3】[机器学习系列之手把手教你实现一个决策树](https://www.ibm.com/developerworks/cn/analytics/library/machine-learning-hands-on4-decision-tree/index.html)  \n",
        "【4】[机器学习系列之手把手教你实现一个分类回归树](https://www.ibm.com/developerworks/cn/analytics/library/machine-learning-hands-on5-cart-tree/index.html?ca=drs-)  \n",
        "【5】[CART决策树(Decision Tree)的Python源码实现](https://zhuanlan.zhihu.com/p/32164933)  \n",
        "【6】[机器学习算法实践-决策树(Decision Tree)](https://zhuanlan.zhihu.com/p/27905967)  \n",
        "【7】[决策树算法的Python实现](https://zhuanlan.zhihu.com/p/20794583)  \n",
        "【8】[决策树算法原理(上)](https://www.cnblogs.com/pinard/p/6050306.html)  \n",
        "【9】[决策树算法原理(下)](https://www.cnblogs.com/pinard/p/6053344.html)  \n",
        "【10】[决策树（decision tree）(二)——剪枝](https://blog.csdn.net/u012328159/article/details/79285214)  \n",
        "【11】[决策树之决策树剪枝](https://zhuanlan.zhihu.com/p/30296061)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRH41xFlKd4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUz0HmxnP8QN",
        "colab_type": "text"
      },
      "source": [
        "## 数据集\n",
        "关于判断某水果是否为苹果的6条数据。数据集前两列分别代表两个特征，分别是圆的和红的。数据集第三列代表类别。拿第一条数据为例，指的是圆的和红的水果是苹果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw0SKzd2Kd2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDataSet():\n",
        "    dataSet = [[1, 1, 'yes'],\n",
        "               [1, 1, 'yes'],\n",
        "               [1, 0, 'no'],\n",
        "               [0, 1, 'no'],\n",
        "               [1, 1, 'yes'],\n",
        "               [1, 1, 'no']]\n",
        "    labels = ['round','red']\n",
        "    return dataSet, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TThbRG-eNLud",
        "colab_type": "text"
      },
      "source": [
        "## 计算熵\n",
        "待分类的事物可能划分在多个类别中，则符号$x_i$的信息是:\n",
        "$$I(x_i) = -\\log_2(P(x_{i}))$$\n",
        " $P(x_i)$ 越大，则 $I(x_i)$ 越小，即 $x_i$ 的概率越大，则 $x_i$ 包含的信息越少 \n",
        "\n",
        "信息熵：平均一个事件发生带来的信息量大小，也就是信息量的期望值：\n",
        "$$H = \\sum_{i=1}^{n}H(x_{i}) = -\\sum_{i=1}^{n}P(x_{i})\\log_2(P(x_{i}))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYMNQK-BKd0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算数据集的entropy\n",
        "def calcEntropy(dataSet):\n",
        "    totalNum = len(dataSet)\n",
        "    labelNum = {}\n",
        "    entropy = 0\n",
        "    for data in dataSet:\n",
        "        label = data[-1]\n",
        "        if label in labelNum:\n",
        "            labelNum[label] += 1\n",
        "        else:\n",
        "            labelNum[label] = 1\n",
        "\n",
        "    for key in labelNum:\n",
        "        p = labelNum[key] / totalNum\n",
        "        entropy -= p * log2(p)\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def calcEntropyForFeature(featureList):\n",
        "    totalNum = len(featureList)\n",
        "    dataNum = {}\n",
        "    entropy = 0\n",
        "    for data in featureList:\n",
        "        if data in dataNum:\n",
        "            dataNum[data] += 1\n",
        "        else:\n",
        "            dataNum[data] = 1\n",
        "\n",
        "    for key in dataNum:\n",
        "        p = dataNum[key] / totalNum\n",
        "        entropy -= p * log2(p)\n",
        "    return entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxGjeGHYOQOY",
        "colab_type": "text"
      },
      "source": [
        " ## ID3决策树选择最优特征\n",
        " 首先计算数据集的初始信息熵，然后循环计算按不同的特征划分后的数据集的信息熵，前一个信息熵减去后一个信息熵的差值就是信息增益。选择信息增益最大的那个特征作为最优特征。  \n",
        " 数据集信息熵：\n",
        " $$H(D) = -\\sum^K_{k=1}\\frac{|C_k|}{|D|}\\log\\frac{|C_k|}{|D|}$$\n",
        "\n",
        " 条件熵：\n",
        "\n",
        " $$H{(D|A)} = \\sum_{i=1}^{n}P(D_{i})H(D_{j}) = \\sum_{i=1}^{n}\\frac{|D_i|}{|D|}\\sum^K_{k=1}\\frac{|D_{ik}|}{|D_i|}\\log\\frac{|D_{ik}|}{|D_i|}$$\n",
        "\n",
        "信息增益：\n",
        " $$G(D,A) = H(D) - H{(D|A)}$$\n",
        "\n",
        " 假设训练数据集为 $D$，样本容量为 $|D|$ ,有 $k$ 个类别 $C_k$ ，$|C_k|$ 为类别 $C_k$  的样本个数。某一特征 $A$ 有 $n$ 个不同的取值 $a_1,a_2,\\cdots,a_n$ 。根据特征 $A$ 的取值可将数据集 $D$ 划分为 $n$ 个子集 $D_1,D_2,\\cdots,D_n$ , $|D_i|$ 为 $D_i$ 的样本个数。并记子集 $D_i$ 中属于类 $C_k$ 的样本的集合为 $|D_{ik}|$ 为 $D_{ik}$ 的样本个数\n",
        "\n",
        " <font face=楷体 color=brown size=5>缺点</font> ：信息增益偏向取值较多的特征，如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDLXBcrKdt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#选择最优划分属性ID3\n",
        "def chooseBestFeatureID3(dataSet, labels):\n",
        "    bestFeature = 0\n",
        "    initialEntropy = calcEntropy(dataSet)\n",
        "    biggestEntropyG = 0\n",
        "    for i in range(len(labels)):\n",
        "        currentEntropy = 0\n",
        "        feature = [data[i] for data in dataSet]\n",
        "        subSet = splitDataSetByFeature(i, dataSet)\n",
        "        totalN = len(feature)\n",
        "        for key in subSet:\n",
        "            prob = len(subSet[key]) / totalN\n",
        "            currentEntropy += prob * calcEntropy(subSet[key])\n",
        "        entropyGain = initialEntropy - currentEntropy\n",
        "        if(biggestEntropyG < entropyGain):\n",
        "            biggestEntropyG = entropyGain\n",
        "            bestFeature = i\n",
        "    return bestFeature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOPIO7RYPtRN",
        "colab_type": "text"
      },
      "source": [
        "## C4.5决策树选择最优特征\n",
        "选择时需要选信息增益比最大的特征作为最优特征。首先计算数据集的初始信息熵，然后循环计算按不同的特征划分后的数据集的信息熵，前一个信息熵减去后一个信息熵的差值就是信息增益。信息增益除以数据集关于某特征取值的熵就是信息增益比。最后将信息增益比最大的那个特征作为最优特征。\n",
        "\n",
        "特征 $A$ 对训练数据集 $D$ 的信息增益比定义为其信息增益与训练集$D$关于特征$A$的值的熵之比\n",
        "$$G_R(D|A) = \\frac{G(D,A)}{H_A(D)}$$\n",
        "\n",
        "其中：\n",
        " $$H_A(D) = -\\sum^n_{i=1}\\frac{|D_i|}{|D|}\\log\\frac{|D_i|}{|D|}$$\n",
        "\n",
        "<font face=楷体 color=yellow size=5>增益比</font>  \n",
        "在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大\n",
        "\n",
        "<font face=楷体 color=brown size=5>缺点</font> ：信息增益比偏向取值较少的特征    \n",
        "<font face=楷体 color=green size=5>原因</font> ：当特征取值较少时$H_A(D)$的值较小，因此其倒数较大，因而偏向取值较少的特征"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSED-raDKdsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#选择最优划分属性C4.5\n",
        "def chooseBestFeatureC45(dataSet, labels):\n",
        "    bestFeature = 0\n",
        "    initialEntropy = calcEntropy(dataSet)\n",
        "    biggestEntropyGR = 0\n",
        "    for i in range(len(labels)):\n",
        "        currentEntropy = 0\n",
        "        feature = [data[i] for data in dataSet]\n",
        "        entropyFeature = calcEntropyForFeature(feature)\n",
        "        subSet = splitDataSetByFeature(i, dataSet)\n",
        "        totalN = len(feature)\n",
        "        for key in subSet:\n",
        "            prob = len(subSet[key]) / totalN\n",
        "            currentEntropy += prob * calcEntropy(subSet[key])\n",
        "        entropyGain = initialEntropy - currentEntropy\n",
        "        entropyGainRatio = entropyGain / entropyFeature\n",
        "\n",
        "        if(biggestEntropyGR < entropyGainRatio):\n",
        "            biggestEntropyGR = entropyGainRatio\n",
        "            bestFeature = i\n",
        "    return bestFeature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqjjCTANOjLr",
        "colab_type": "text"
      },
      "source": [
        "## 按特征划分数据集\n",
        "按数据集的某个特征划分数据集。先统计该特征的取值，然后按不同取值划分数据集。  \n",
        "<font face=楷体 color=red size=5>注意</font>：划分后的数据集中将不再包含该特征"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOM22jstKdox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitDataSetByFeature(i, dataSet):\n",
        "    subSet = {}\n",
        "    feature = [data[i] for data in dataSet]\n",
        "    for j in range(len(feature)):\n",
        "        if feature[j] not in subSet:\n",
        "            subSet[feature[j]] = []\n",
        "\n",
        "        splittedDataSet = dataSet[j][:i]\n",
        "        splittedDataSet.extend(dataSet[j][i + 1:])\n",
        "        subSet[feature[j]].append(splittedDataSet)\n",
        "    return subSet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDexahTFO0Gn",
        "colab_type": "text"
      },
      "source": [
        "## 结束条件\n",
        "ID3决策树出现两种条件则需要结束对数据集的划分\n",
        "- 划分后的数据集属于同一类别\n",
        "- 没有特征值可继续划分。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQdlrrpHKvM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkIsOneCateg(newDataSet):\n",
        "    flag = False\n",
        "    categoryList = [data[-1] for data in newDataSet]\n",
        "    category = set(categoryList)\n",
        "    if(len(category) == 1):\n",
        "        flag = True\n",
        "    return flag\n",
        "\n",
        "\n",
        "def majorityCateg(newDataSet):\n",
        "    categCount = {}\n",
        "    categList = [data[-1] for data in newDataSet]\n",
        "    for c in categList:\n",
        "        if c not in categCount:\n",
        "            categCount[c] = 1\n",
        "        else:\n",
        "            categCount[c] += 1\n",
        "    sortedCateg = sorted(categCount.items(), key = lambda x:x[1], reverse = True)\n",
        "\n",
        "    return sortedCateg[0][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXn-0Mb3PIuc",
        "colab_type": "text"
      },
      "source": [
        "## 创建决策树\n",
        "递归创建决策树:\n",
        "- 首先选择最优划分特征\n",
        "- 然后按最优特征划分数据集\n",
        "- 对于划分后的数据集，先判断是否达到结束条件，如果是，则返回类别，并停止对数据子集的划分；如果不是，则继续递归构建决策树"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPGchGEBKvEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#创建ID3树\n",
        "def createDecisionTreeID3(decisionTree, dataSet, labels):\n",
        "    bestFeature = chooseBestFeatureID3(dataSet, labels)\n",
        "    decisionTree[labels[bestFeature]] = {}\n",
        "    currentLabel = labels[bestFeature]\n",
        "    subSet = splitDataSetByFeature(bestFeature, dataSet)\n",
        "    del(labels[bestFeature])\n",
        "    newLabels = labels[:]\n",
        "    for key in subSet:\n",
        "        newDataSet = subSet[key]\n",
        "        flag = checkIsOneCateg(newDataSet)\n",
        "        if(flag == True):\n",
        "            decisionTree[currentLabel][key] = newDataSet[0][-1]\n",
        "        else:\n",
        "            if (len(newDataSet[0]) == 1): #无特征值可划分\n",
        "                decisionTree[currentLabel][key] = majorityCateg(newDataSet)\n",
        "            else:\n",
        "                decisionTree[currentLabel][key] = {}\n",
        "                createDecisionTreeID3(decisionTree[currentLabel][key], newDataSet, newLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz0PXDZVKdlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 创建C4.5树\n",
        "def createDecisionTreeC45(decisionTree, dataSet, labels):\n",
        "    bestFeature = chooseBestFeatureC45(dataSet, labels)\n",
        "    decisionTree[labels[bestFeature]] = {}\n",
        "    currentLabel = labels[bestFeature]\n",
        "    subSet = splitDataSetByFeature(bestFeature, dataSet)\n",
        "    del (labels[bestFeature])\n",
        "    newLabels = labels[:]\n",
        "    for key in subSet:\n",
        "        newDataSet = subSet[key]\n",
        "        flag = checkIsOneCateg(newDataSet)\n",
        "        if (flag == True):\n",
        "            decisionTree[currentLabel][key] = newDataSet[0][-1]\n",
        "        else:\n",
        "            if (len(newDataSet[0]) == 1):  # 无特征值可划分\n",
        "                decisionTree[currentLabel][key] = majorityCateg(newDataSet)\n",
        "            else:\n",
        "                decisionTree[currentLabel][key] = {}\n",
        "                createDecisionTreeC45(decisionTree[currentLabel][key], newDataSet, newLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9VHjhjPhIf",
        "colab_type": "text"
      },
      "source": [
        "## 将测试数据分类\n",
        "如果到达叶节点，则返回该分类；否则，继续尝试其他特征，直到到达叶节点为止，然后返回该分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtoOoUbbK4JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#测试数据分类\n",
        "def classifyTestData(decisionTree, testData):\n",
        "    result1 = decisionTree['round'][testData[0]]\n",
        "    if(type(result1) == str): category = result1\n",
        "    else:\n",
        "        category = decisionTree['round'][testData[0]]['red'][testData[1]]\n",
        "    return category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aJwwWpf39FC",
        "colab_type": "code",
        "outputId": "80e2cee3-ac8d-46c0-c1b1-a8a42877dba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    dataSetID3, labelsID3 = createDataSet()\n",
        "    testData1 = [0, 1]\n",
        "    testData2 = [1, 1]\n",
        "    bestFeatureID3 = chooseBestFeatureID3(dataSetID3, labelsID3)\n",
        "    decisionTreeID3 = {}\n",
        "    createDecisionTreeID3(decisionTreeID3, dataSetID3, labelsID3)\n",
        "    print(\"ID3 decision tree: \", decisionTreeID3)\n",
        "    category1ID3 = classifyTestData(decisionTreeID3, testData1)\n",
        "    print(testData1 , \", classified as by ID3: \" , category1ID3)\n",
        "    category2ID3 = classifyTestData(decisionTreeID3, testData2)\n",
        "    print(testData2 , \", classified as by ID3: \" , category2ID3)\n",
        "\n",
        "    dataSetC45, labelsC45 = createDataSet()\n",
        "    bestFeatureC45 = chooseBestFeatureC45(dataSetC45, labelsC45)\n",
        "    decisionTreeC45 = {}\n",
        "    createDecisionTreeC45(decisionTreeC45, dataSetC45, labelsC45)\n",
        "    print(\"C4.5 decision tree: \", decisionTreeC45)\n",
        "    category1C45 = classifyTestData(decisionTreeC45, testData1)\n",
        "    print(testData1 , \", classified as by C4.5: \" , category1C45)\n",
        "    category2C45 = classifyTestData(decisionTreeC45, testData2)\n",
        "    print(testData2 , \", classified as by C4.5: \" , category2C45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID3 decision tree:  {'round': {1: {'red': {1: 'yes', 0: 'no'}}, 0: 'no'}}\n",
            "[0, 1] , classified as by ID3:  no\n",
            "[1, 1] , classified as by ID3:  yes\n",
            "C4.5 decision tree:  {'round': {1: {'red': {1: 'yes', 0: 'no'}}, 0: 'no'}}\n",
            "[0, 1] , classified as by C4.5:  no\n",
            "[1, 1] , classified as by C4.5:  yes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}